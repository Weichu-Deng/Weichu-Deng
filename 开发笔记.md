## Robots协议

  Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots ExclusionProtocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。
  最简单的robots.txt只有两条规则：

+ User-agent：指定对哪些爬虫生效
+ Disallow：指定要屏蔽的网址

## Scrapy框架

安装命令：

```PowerShell
pip install Scrapy
```

提示报错：

```PowerShell
Could not fetch URL https://pypi.tuna.tsinghua.edu.cn/simple/scrapy/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.tuna.tsinghua.edu.cn', port=443): Max retries exceeded with url: /simple/scrapy/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:777)'),)) - skipping
ERROR: Could not find a version that satisfies the requirement Scrapy (from versions: none)
ERROR: No matching distribution found for Scrapy
Could not fetch URL https://pypi.tuna.tsinghua.edu.cn/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.tuna.tsinghua.edu.cn', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:777)'),)) - skipping
```

解决办法，依次安装依赖库：

```PowerShell
pip install lxml
pip install parsel
pip install w3lib
pip install twisted
pip install cryptography
pip install pyOpenSSL
```

开始新项目：

```PowerShell
scrapy startproject mySpider
```

在当前 `item.py`所在目录下输入命令，将在mySpider/spider目录下创建一个名为itcast的爬虫，并指定爬取域的范围：

```PowerShell
scrapy genspider itcast "itcast.cn"
```

### Python yield关键字

 一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值

## Selenium库

Selenium是一个自动化web测试工具,可以模拟用户浏览网页的行为，因此可以用来爬取动态加载的网页,实现点击,翻页,滚动的效果
代码片段例子：

```python
driver = webdriver.Edge() #初始化一个浏览器引擎，需要自己下载并存入python安装的路径
driver.execute_script("window.scrollTo(0,document.body.scrollHeight);")# 执行js脚本，滚轮
driver.find_element_by_xpath('//*[@id="hot_scroll"]') # 通过Xpath定位元素
driver.close() # 关闭浏览器，否则会耗费大量内存
```

## mongodb

设置成服务，在 `services.msc`中将服务改成手动

```bash
mongod --dbpath "E:\MongoDB\data\db" --logpath "E:\MongoDB\data\log\mongo.log" -install -serviceName "MongoDB"
```

启动：`net start mongodb`
启动报错：
![alt ](md图片\1.jpg)
  **权限不够用，用管理员身份打开**

### Linux 启动

**指定配置文件**

```bash
mongod --dbpath /var/lib/mongo --logpath /var/log/mongodb/mongod.log -f ~/mongodb/mongodb.conf

sudo mongod -f mongodb.conf
```

**查看运行情况**

```shell
tail -10f /var/log/mongodb/mongod.log
```

**添加环境变量**

```
export PATH=/usr/local/mongodb4/bin:$PATH
```

``tail -10f /var/log/mongodb/mongod.log``

mongodb.conf：

```conf
#日志文件位置
logpath=/home/dwc/mongodb/data/logs/mongodb.log

# 以追加方式写入日志
logappend=true

# 是否以守护进程方式运行
fork = true

# 默认27017
#port = 27017

# 数据库文件位置
dbpath=/home/dwc/mongodb/data/db

# 启用定期记录CPU利用率和 I/O 等待
#cpu = true

# 是否以安全认证方式运行，默认是不认证的非安全方式
noauth = true
#auth = true

#默认127.0.0.1为只允许本地连接；0.0.0.0为不限制；多个指定服务器用，连接
bind_ip=0.0.0.0
```

python使用 `pymongo`连接：

```python
import pymongo
myclient = pymongo.MongoClient("mongodb://localhost:27017/")
mydb = myclient["scraped_urls"]
mycol = mydb["urls"]
mycol.insert_one({"_id":'1'})
```

pymongo使用 `find`查询**速度慢**的问题：
解决办法：将代码放到mongodb所在服务器上执行

**命令行操作**

```bash
> use scraped_urls
switched to db scraped_urls
> db.urls.find({_id:/people/}).count()
1387
> db.urls.remove({_id:/people/})
```

## undetected_chromedriver 隐藏浏览器驱动属性

直接用 `Selenium`打开知乎网站会被识别出来，无法进行滚动，点击翻页等操作

```JavaScript
window.navigator.webdriver
```

用普通浏览器执行则显示 `undefine`,用 `webdriver`执行则会显示 `true`,还有很多类似属性会被网站识别出来，限制爬取
**解决办法：**使用 `undetected_chromedriver`库可以隐藏这些属性
安装命令：

```Shell
pip install undetected_chromedriver
```

## 关闭防火墙

```Shell
systemctl stop firewalld.service #停止firewall
```

## Linux 后台运行命令，关闭终端仍然运行

后台运行flask项目

```shell
nohup python app.py 
```

关闭方法,先找到进程号，然后关闭进程

```shell
ps -aux | grep "python app.py" 
kill -9 PID
```

## 查看端口占用

```shell
netstat -anp | grep 8080
```

## Linux密码错误次数过多导致被锁定

用 `root`登录然后重置

```shell
pam_tally2 --user=gzdx
pam_tally2 --user=gzdx --reset
```

`bash: pam_tally2: command not found`

添加环境临时环境变量 `export PATH=/usr/bin:/usr/sbin:/bin:/sbin`

## git更新
```
git add --all
git commit -m "更新 "
git push -u origin main
git config --global --unset http.proxy （time out）
```